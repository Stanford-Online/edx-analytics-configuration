---

- name: Provision cluster
  hosts: localhost
  gather_facts: False
  vars:
    # The following vars should probably be overridden
    - name: $CLUSTER_NAME
    - master_instance_num: 1
    - master_instance_type: m4.xlarge
    - core_instance_num: 2
    - core_instance_type: m4.xlarge
    - core_volume_size: 500
    - task_instance_num: 1
    - task_instance_type: m4.xlarge
    - instance_groups:
        master:
          num_instances: "{{ master_instance_num }}"
          type: "{{ master_instance_type }}"
          market: ON_DEMAND
        core:
          num_instances: "{{ core_instance_num }}"
          type: "{{ core_instance_type }}"
          volume_size: "{{ core_volume_size }}"
          market: ON_DEMAND
        task:
          num_instances: "{{ task_instance_num }}"
          type: "{{ task_instance_type }}"
          market: ON_DEMAND
    - bootstrap_actions: {}
    - steps:
      - type: script
        name: "Install MySQL connector for Sqoop"
        step_args: [ "s3://stanford-edx-analytics-prod-472/packages/install-sqoop", "s3://stanford-edx-analytics-prod-472/packages" ]
        # You may want to set this to CANCEL_AND_WAIT while debugging step failures.
        action_on_failure: TERMINATE_JOB_FLOW
    - applications:
      - name: hadoop
      - name: ganglia
      - name: hive
      - name: sqoop-sandbox
    - configurations:
      - classification: mapred-site
        properties:
          mapreduce.framework.name: 'yarn'
          mapreduce.jobtracker.retiredjobs.cache.size: '50'
          mapreduce.reduce.shuffle.input.buffer.percent: '0.20'
          mapreduce.map.java.opts: '-Xmx2458m'
          mapreduce.reduce.java.opts: '-Xmx4916m'
          mapreduce.map.memory.mb: '3072'
          mapreduce.reduce.memory.mb: '6144'
      - classification: yarn-site
        properties:
          yarn.resourcemanager.max-completed-applications: '5'
      - classification: core-site
        properties:
          fs.s3n.endpoint: "s3.amazonaws.com"
    - ec2_attributes: {}
    - region: 'us-west-1'
    - keypair_name: "{{ lookup('env', 'AWS_KEYPAIR_NAME') }}"
    - role: emr
    - ami_version: 4.7.2
    - release_label: 'emr-4.7.2'
    - vpc_subnet_id: subnet-9215e8f7
    - user_info: []
    - log_uri: s3://stanford-data-cluster-logs/
    - additional_master_security_groups: 
      - sg-e6cc3383
    - additional_slave_security_groups: 
      - sg-e1cc3384
  tasks:
    - name: provision EMR cluster
      local_action:
        module: emr
        name: "{{ name }}"
        region: "{{ region }}"
        keypair_name: "{{ keypair_name }}"
        vpc_subnet_id: "{{ vpc_subnet_id }}"
        log_uri: "{{ log_uri }}"
        visible_to_all_users: yes
        job_flow_role: "{{ role }}"
        ami_version: "{{ ami_version }}"
        release_label: "{{ release_label }}"
        instance_groups: $instance_groups
        bootstrap_actions: $bootstrap_actions
        steps: $steps
        applications: $applications
        configurations: $configurations
        ec2_attributes: $ec2_attributes
        additional_master_security_groups: $additional_master_security_groups
        additional_slave_security_groups: $additional_slave_security_groups
      register: jobflow

    - name: add master to group
      local_action: >
        add_host hostname={{ jobflow.master_private_ip }} groupname=launched_master ansible_ssh_user=hadoop ansible_connection=ssh

    - name: display master IP address
      debug: msg={{ jobflow.master_private_ip }}

    - name: display job flow ID
      debug: msg={{ jobflow.jobflow_id }}


- name: Configure SSH access to cluster
  hosts: launched_master
  gather_facts: False
  sudo: True
  roles:
    - user
